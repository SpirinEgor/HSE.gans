{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmfUbCUiV57S"
   },
   "source": [
    "# Домашнее задание 1. Autoencoders & Frechet Inception Distance\n",
    "\n",
    "\n",
    "В этом домашнем задании вам предлагается вспомнить то, что происходило на семинарах 1-2, написать свой автоэнкодер на CIFAR10 и использовать эмбеддинги от этого автоэнкодера чтобы посчитать Frechet Inception Distance (FID) между разными классами в CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sok-J_gV57b"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFHjsDYVV57c"
   },
   "source": [
    "Будем использовать torchvision для работы с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTSsFjS3V57d"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), lambda x: (x * 2) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FmbsKiFV57d"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.CIFAR10(\"./cifar\", train=True, transform=transform, download=True)\n",
    "val_dataset = datasets.CIFAR10(\"./cifar\", train=False, transform=transform, download=True)\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmVkCw6lV57e"
   },
   "source": [
    "Раз мы используем нормализацию картинок, то чтобы их нарисовать - надо их обратно разнормализировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BV5GrU7ZV57f"
   },
   "outputs": [],
   "source": [
    "def denormalize_image(norm_image):\n",
    "    return (norm_image + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFkP-SBTV57f"
   },
   "outputs": [],
   "source": [
    "text_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for index, (image, label) in enumerate(train_dataset):\n",
    "    plt.subplot(5, 5, index + 1)\n",
    "    plt.imshow(denormalize_image(image.permute(1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(text_labels[label])\n",
    "    if index == 24:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFB6-mbQV57f"
   },
   "source": [
    "Размерность картинок: 3 канала 32х32 пикселя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqj9X1rAV57g"
   },
   "outputs": [],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJVhwli3V57g"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "720dLAo3V57g"
   },
   "source": [
    "### Задание 1. Обучить AE (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKWrzmPyV57h"
   },
   "source": [
    "Постройте свой AE, можете использовать любые блоки которые вам кажутся необходимыми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqwUR0ucV57h"
   },
   "source": [
    "<img src='https://miro.medium.com/max/1400/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qphXadNxV57h"
   },
   "source": [
    "Напишите классы Encoder и Decoder\n",
    "\n",
    "хинт: вам пригодятся nn.AvgPool2d/nn.MaxPool2d/Conv2d в энкодере и nn.Upsample/nn.ConvTranspose2d в декодере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DenoisingBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_ch: int,\n",
    "        out_ch: int,\n",
    "        stride: int = 1,\n",
    "        bias: bool = False,\n",
    "        upsample: bool = False,\n",
    "        lr_cf: float = 0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, (3, 3), stride=stride, padding=1, bias=bias)\n",
    "        self.norm = nn.BatchNorm2d(out_ch)\n",
    "        self.act = nn.LeakyReLU(lr_cf)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False, recompute_scale_factor=False)\n",
    "        x = x + torch.randn_like(x) * 0.05\n",
    "        return self.act(self.norm(self.conv(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "-1tzXotrV57h",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c03ce36d39944198a2a0fb722fbb18f",
     "grade": false,
     "grade_id": "cell-4aa3f7e8f24f1669",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int = 128, h_channels: int = 64):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            DenoisingBlock(3, h_channels, stride=2),\n",
    "            DenoisingBlock(h_channels, h_channels, stride=2),\n",
    "            DenoisingBlock(h_channels, h_channels, stride=2),\n",
    "            DenoisingBlock(h_channels, h_channels, stride=2),\n",
    "            DenoisingBlock(h_channels, h_channels, stride=1).conv,\n",
    "        )\n",
    "        self.linear = nn.Linear(h_channels * 2 * 2, latent_dim)\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "        convolved = self.blocks(images)\n",
    "        return self.linear(convolved.view(images.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjhaT8OiV57i"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "noise = torch.rand(1, 3, 32, 32) - 1\n",
    "assert encoder(noise).view(-1).shape[0] < 1*3*32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "4MX32-T0V57i",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "772a7f9580d3c35e19ccf64815b96032",
     "grade": false,
     "grade_id": "cell-84f57c3cddb183f2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int = 128, h_channels: int = 64):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(latent_dim, h_channels * 2 * 2)\n",
    "        self.h_channels = h_channels\n",
    "        self.blocks = nn.Sequential(\n",
    "            DenoisingBlock(h_channels, h_channels, upsample=True),\n",
    "            DenoisingBlock(h_channels, h_channels, upsample=True),\n",
    "            DenoisingBlock(h_channels, h_channels, upsample=True),\n",
    "            DenoisingBlock(h_channels, h_channels, upsample=True),\n",
    "            DenoisingBlock(h_channels, 3).conv,\n",
    "        )\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "        sized = self.linear(images)\n",
    "        sized = sized.view(-1, self.h_channels, 2, 2)\n",
    "        return self.blocks(sized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAGi6UwGV57j"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder()\n",
    "noise = torch.rand(1, 3, 32, 32)\n",
    "emb = encoder(noise)\n",
    "assert decoder(emb).shape == (1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LnKqtIoX0O6"
   },
   "source": [
    "Посчитаем скор классификации картинок по эмбеддингам необученного энкодора, и в конце сравним с обученным. Для ускорения расчета, мы используем только часть трейна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Vp7mRGaWV57j",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fe4fb5421d5aac174943ef9d0c66386",
     "grade": false,
     "grade_id": "cell-e0c68a9117bd6efc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def classification_score(m_encoder, t_dataset, v_dataset, cur_device):\n",
    "    m_encoder.eval()\n",
    "    torch.manual_seed(0)\n",
    "    t_dataset = Subset(t_dataset, torch.randperm(len(t_dataset))[:5000])\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for image, label in tqdm(t_dataset):\n",
    "        image = image.to(cur_device)\n",
    "        with torch.no_grad():\n",
    "            emb = m_encoder(image[None, ...])\n",
    "        X_train.append(emb.cpu().numpy().reshape(-1))\n",
    "        y_train.append(label)\n",
    "    X_train = np.stack(X_train)\n",
    "    y_train = np.stack(y_train)\n",
    "    clf = GradientBoostingClassifier(n_estimators=10, max_depth=5, verbose=1, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    for image, label in tqdm(v_dataset):\n",
    "        image = image.to(cur_device)\n",
    "        with torch.no_grad():\n",
    "            emb = m_encoder(image[None, ...])\n",
    "        X_val.append(emb.cpu().numpy().reshape(-1))\n",
    "        y_val.append(label)\n",
    "    X_val = np.stack(X_val)\n",
    "    y_val = np.stack(y_val)\n",
    "    return clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiUKGVSNV57j"
   },
   "outputs": [],
   "source": [
    "classification_score(Encoder(), train_dataset, val_dataset, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cj5pns5bV57k"
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrQDQBktV57k"
   },
   "outputs": [],
   "source": [
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3c86u9OaV57k"
   },
   "outputs": [],
   "source": [
    "params = chain(encoder.parameters(), decoder.parameters())\n",
    "optim = torch.optim.AdamW(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iikqNFUJYNwG"
   },
   "source": [
    "Напишите функцию train, которая обучает энкодер и декодер на всем трейн сете, возвращает среднюю MSE ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def l1_loss(x: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.mean(torch.sum(torch.abs(x), dim=1))\n",
    "\n",
    "def calculate_sparse_loss(m_encoder: Encoder, m_decoder: Decoder, images: torch.Tensor) -> torch.Tensor:\n",
    "    loss = 0\n",
    "    for block in m_encoder.blocks[:-1]:\n",
    "        images = block.conv(images)\n",
    "        loss += l1_loss(images)\n",
    "        images = block.act(block.norm(images))\n",
    "    images = m_encoder.blocks[-1](images)\n",
    "    loss += l1_loss(images)\n",
    "    images = m_encoder.linear(images.view(images.shape[0], -1))\n",
    "\n",
    "    images = m_decoder.linear(images)\n",
    "    images = images.view(-1, m_decoder.h_channels, 2, 2)\n",
    "    for block in m_decoder.blocks[:-1]:\n",
    "        images = block.conv(images)\n",
    "        loss += l1_loss(images)\n",
    "        images = block.act(block.norm(images))\n",
    "    images = m_decoder.blocks[-1](images)\n",
    "    loss += l1_loss(images)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "HBLKFU9KV57k",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0f8a0eede23d31627c0d7998357b090",
     "grade": false,
     "grade_id": "cell-ebb87a90255a8f01",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train(loader, optimizer, m_encoder, m_decoder, cur_device):\n",
    "    m_encoder.train()\n",
    "    m_decoder.train()\n",
    "    losses = []\n",
    "\n",
    "    loader_bar = tqdm(loader, leave=False, desc=\"Training\")\n",
    "    postfix = {}\n",
    "    for b_images, _ in loader_bar:\n",
    "        b_images = b_images.to(cur_device)\n",
    "        noise = torch.randn_like(b_images, requires_grad=False) * 0.1\n",
    "        noised_images = torch.clamp(b_images + noise, -1, 1)\n",
    "\n",
    "        embeddings = m_encoder(noised_images)\n",
    "        rec_images = m_decoder(embeddings)\n",
    "        mse_loss = F.mse_loss(b_images, rec_images)\n",
    "        cur_loss = mse_loss + 0.001 * calculate_sparse_loss(m_encoder, m_decoder, b_images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cur_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(mse_loss.item())\n",
    "        postfix[\"loss\"] = losses[-1]\n",
    "        loader_bar.set_postfix(postfix)\n",
    "\n",
    "    loader_bar.close()\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdRMv148V57l"
   },
   "outputs": [],
   "source": [
    "temp_dataloader = DataLoader(Subset(train_dataset, [0]), batch_size=1)\n",
    "loss = train(temp_dataloader, optim, encoder, decoder, device)\n",
    "assert type(loss) == float\n",
    "assert 0 < loss < 1\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tWbFMfMYklw"
   },
   "source": [
    "Напишите функцию eval, которая возвращает среднюю MSE ошибку по всему валидационному сету\n",
    "\n",
    "хинт: не забывайте отключать расчет градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "NKQ4yyRxV57l",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec975b61f53d88992725176e078684a9",
     "grade": false,
     "grade_id": "cell-8617fadbc72dc0ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def eval(loader, m_encoder, m_decoder, cur_device):\n",
    "    m_encoder.eval()\n",
    "    m_decoder.eval()\n",
    "    losses = []\n",
    "    for b_images, _ in tqdm(loader, leave=False, desc=\"Evaluation\"):\n",
    "        b_images = b_images.to(cur_device)\n",
    "        with torch.no_grad():\n",
    "            embeddings = m_encoder(b_images)\n",
    "            rec_images = m_decoder(embeddings)\n",
    "            cur_loss = F.mse_loss(b_images, rec_images)\n",
    "        losses.append(cur_loss.item())\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGRQQDsAV57l"
   },
   "outputs": [],
   "source": [
    "temp_dataloader = DataLoader(Subset(train_dataset, [0]), batch_size=1)\n",
    "loss = eval(temp_dataloader, encoder, decoder, device)\n",
    "assert type(loss) == float\n",
    "assert 0 < loss < 1\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOpcztOXY5tw"
   },
   "source": [
    "Функция full_train возвращает обученный энкодер и декодер. Чтобы пройти ограничения по времени, обучите модель, а затем добавьте загрузку предобученных весов в самое начало функции. Можете использовать шаблон для загрузки весов из Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "cRMKeGj4V57m",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfa5c8531290b0e03a9f54967cdc8f44",
     "grade": false,
     "grade_id": "cell-4956ac12620a6286",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def full_train(\n",
    "    cur_device: torch.device,\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    n_epochs: int = 30,\n",
    "    lr: float = 1e-3,\n",
    "):\n",
    "    m_encoder = Encoder().to(cur_device)\n",
    "    m_decoder = Decoder().to(cur_device)\n",
    "    optimizer = torch.optim.AdamW(chain(m_encoder.parameters(), m_decoder.parameters()), lr=lr)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    postfix = {}\n",
    "    epoch_bar = trange(n_epochs, desc=\"Epochs\", postfix=postfix)\n",
    "    for e in epoch_bar:\n",
    "        e_train_loss = train(train_dataloader, optimizer, m_encoder, m_decoder, cur_device)\n",
    "        train_loss.append(e_train_loss)\n",
    "\n",
    "        e_val_loss = eval(val_dataloader, m_encoder, m_decoder, cur_device)\n",
    "        val_loss.append(e_val_loss)\n",
    "\n",
    "        postfix[\"Train MSE loss\"] = e_train_loss\n",
    "        postfix[\"Validation MSE loss\"] = e_val_loss\n",
    "        epoch_bar.set_postfix(postfix)\n",
    "\n",
    "    epoch_bar.close()\n",
    "\n",
    "    plt.plot(train_loss, label=\"train\")\n",
    "    plt.plot(val_loss, label=\"val\")\n",
    "    plt.legend()\n",
    "    plt.title(\"MSE Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    return m_encoder, m_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAAZSOOSV57m"
   },
   "outputs": [],
   "source": [
    "encoder, decoder = full_train(device, train_loader, val_loader, n_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "makedirs(\"weights\", exist_ok=True)\n",
    "torch.save(encoder.state_dict(), join(\"weights\", \"encoder.pth\"))\n",
    "torch.save(decoder.state_dict(), join(\"weights\", \"decoder.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "encoder.load_state_dict(torch.load(join(\"weights\", \"encoder.pth\"), map_location=device))\n",
    "decoder = Decoder().to(device)\n",
    "decoder.load_state_dict(torch.load(join(\"weights\", \"decoder.pth\"), map_location=device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8285990abb1464178d7ae3e03f63a12",
     "grade": true,
     "grade_id": "cell-84977b8455d7cddd",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "id": "V67NvcU1cWfS"
   },
   "outputs": [],
   "source": [
    "score = classification_score(encoder, train_dataset, val_dataset, device)\n",
    "assert score > 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAyuqGb1V57m"
   },
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "plt.figure(figsize=(5, 25))\n",
    "for index, (image, label) in enumerate(val_loader):\n",
    "    plt.subplot(10, 2, index * 2 + 1)\n",
    "    plt.imshow(denormalize_image(image)[0].permute(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(text_labels[label])\n",
    "    plt.subplot(10, 2, index * 2 + 2)\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        emb = encoder(image)\n",
    "        rec = decoder(emb).cpu()\n",
    "    plt.imshow(denormalize_image(rec)[0].permute(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    if index == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5ZDnTqoV57n"
   },
   "source": [
    "### Задание 2. FID дистанция между классами CIFAR10 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pomp9GXvV57n"
   },
   "source": [
    "В этой части хочется чтобы вы, используя bottleneck репрезентации от AE обученного в прошлой части посчитали FID дистанцию между различными классами CIFAR10 на **валидационной** выборке\n",
    "\n",
    "За копию кода из сети будем снимать баллы\n",
    "\n",
    "Напишите функцию get_representations, которая возвращает defaultdict, где ключ — это номер класса, значение — это список эмбеддингов, полученных из энкодера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "WZrECpZRV57n",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "656e5a00fe2913ff3b199786545ce545",
     "grade": false,
     "grade_id": "cell-25a0eb3002b49c80",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_representations(dataloader, m_encoder, cur_device):\n",
    "    m_encoder.eval()\n",
    "    representations = defaultdict(list)\n",
    "    for b_images, b_labels in tqdm(dataloader):\n",
    "        b_images = b_images.to(cur_device)\n",
    "        with torch.no_grad():\n",
    "            embeddings = m_encoder(b_images)\n",
    "        for emb, label in zip(embeddings, b_labels):\n",
    "            representations[label.item()].append(emb.detach())\n",
    "    return representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPoAkeH5V57n"
   },
   "outputs": [],
   "source": [
    "representations = get_representations(val_loader, encoder, device)\n",
    "assert len(representations) == 10\n",
    "assert len(representations[0]) == 1000\n",
    "assert type(representations[0][0]) == torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2EvLkZ0V57o"
   },
   "source": [
    "Напишите функцию расчета FID\n",
    "$$\\text{FID}=\\left\\|\\mu_{r}-\\mu_{g}\\right\\|^{2}+T_{r}\\left(\\Sigma_{r}+\\Sigma_{g}-2\\left(\\Sigma_{r} \\Sigma_{g}\\right)^{1 / 2}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Ggxsbp-DV57o",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdaaeb0240c3f7db132711576d4d5edf",
     "grade": false,
     "grade_id": "cell-526e5eaf469de953",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_fid(repr1: torch.Tensor, repr2: torch.Tensor) -> float:\n",
    "    mu_r = repr1.mean(0)\n",
    "    mu_g = repr2.mean(0)\n",
    "    term1 = np.linalg.norm(mu_r - mu_g)\n",
    "\n",
    "    sigma_r = np.cov(repr1)\n",
    "    sigma_g = np.cov(repr2)\n",
    "    term2 = np.trace(sigma_r + sigma_g - 2 * np.sqrt(sigma_g * sigma_r))\n",
    "    return term1 + term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "EInd5mGPV57o",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9fdfc471a11af539455925210296fb5",
     "grade": true,
     "grade_id": "cell-04e1ad45f6fb56cf",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "heatmap = np.zeros((10, 10))\n",
    "for label_from in trange(10):\n",
    "    for label_to in range(10):\n",
    "        fid = calculate_fid(\n",
    "            torch.stack(representations[label_from], dim=0).cpu().numpy(),\n",
    "            torch.stack(representations[label_to], dim=0).cpu().numpy()\n",
    "        )\n",
    "        heatmap[label_from, label_to] = fid\n",
    "assert heatmap.shape == (10, 10)\n",
    "assert np.all(heatmap + 1e-5 > 0)\n",
    "airplane_ship = heatmap[0, 8]\n",
    "airplane_frog = heatmap[0, 6]\n",
    "truck_automobile = heatmap[9, 1]\n",
    "truck_dog = heatmap[9, 5]\n",
    "assert airplane_ship < airplane_frog\n",
    "assert truck_automobile < truck_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdeiEykLV57o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(heatmap, linewidth=0.5, xticklabels=text_labels, yticklabels=text_labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw1_ae_fid_autograding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}